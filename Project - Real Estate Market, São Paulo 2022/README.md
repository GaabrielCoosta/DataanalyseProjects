### PROJECT THEME:

  - REAL ESTATE MARKET, SÃO PAULO 2022

[Dashboard](https://app.powerbi.com/view?r=eyJrIjoiYThmMzc4ODEtYWY3Zi00NzExLThkY2ItOGI1ZjdmZWU4N2MxIiwidCI6ImJmYzhlZDQ2LTY3ZTYtNDYzMC04ZDM5LTM3ZWViZTY0NmE1NSJ9)


![Captura de Tela 2023-08-22 às 15 13 49](https://github.com/GaabrielCoosta/DataanalyseProjects/assets/108695592/7761d98c-f6fa-4cb3-8f81-0796662dc5f3)

[![NPM](https://img.shields.io/npm/l/react)](https://github.com/GaabrielCoosta/Changelle_HandTalk/blob/main/LICENSE)
![NPM](https://img.shields.io/static/v1?label=Python&message=3.10&color=<COLOR>&logo=python)

### GENERAL DESCRIPTION OF THE PROJECT
  - All teams must deliver the same specifications, according to their respective theme;
  - You will have to apply the concepts seen during the course to treat, organize and model the data of at least 2 datasets chosen by you following the theme of your team;
  - It must necessarily contain Google Cloud Platform (Cloud Storage), Python, Pandas, SQL, PySpark, Looker Studio, PowerBI, Big Query and MongoDB technologies;

### PRESENTATION

The work will be presented as follows:
  - Each group should be fully responsible for the way in which it will interpret the dataset, presenting assumptions and conclusions from the data;
  - All these situations must be explained. It should start by presenting the dataset, informing where the dataset was obtained from and the main information about it;
  - It should present the functions and tools used in the code;
  - Explain the reason for the chosen dataset;
  - All components (members) must introduce themselves;
  - Technical terms must be used, avoiding the use of slang or colloquial and/or cultural expressions;
  - Each group will have up to 60 minutes to present themselves;
  - The presentation order will be communicated by the professors close to the presentation date;

### MAIN SKILLS TO BE ASSESSED
  - Orality and communication in public;
  - SWOT Analysis: strategic planning tool that helps to assess the strengths, weaknesses, opportunities and threats of a company or project;
  - Storytelling in the presentation of data: the presentation of data can be done in a more effective and engaging way through the storytelling technique. When telling a story, data is presented in a clearer and more understandable way, and the audience is more easily motivated and engaged;
  - Main metrics and KPI's observed: complete definition of which metrics and/or KPI's will be applied to the project, their reasons and strategic definitions;
  - Establish some suggestions for actions: build some suggestions for actions based on the information collected in the project. Actions aimed at campaigns, objectives and segmentations, for example;
  - Ability to argue;
  - Coding skills in Python and use of its libraries;
  - Ability to interpret and analyze data;
  - Ability to implement codes using Pandas and PySpark libraries;
  - Ability to implement queries using the SQL language;
  - Analytical and Interpretive Capacity;
  - Capacity of organization and group;

### MANDATORY REQUIREMENTS
  - The datasets must have different formats (CSV / Json / Sql / NoSql/ Excel, others) and 1 of them must be in CSV;
  - Operations with Pandas (cleaning, transformations and normalizations);
  - Data analysis operations using PySpark with the justification of each of the transformations used with it;
  - Use at least 2 different graphs (python libraries) to represent the data and find possible inconsistencies;
  - The datasets used can be in a foreign language, but in the end they must have their data/columns displayed in the PT-BR language (Use the guidelines discussed in class);
  - The datasets must be saved and operated in cloud storage mandatorily within the GCP platform (Google drive or non-google storage cannot be used);
  - The processed data must be stored in a datalake(Bucket ) , DW(BigQuery) or both;
  - The resulting Dataframe(s) must be in a MongoDB atlas collection (inform the cluster access key);
  - At least 4 analyzes must be carried out within Big Query using the standard SQL language with the description of the queries made;
  - A dashboard must be created in Looker Studio or PowerBI for graphical display of processed data bringing important insights;
  - And it must be demonstrated in a simple workflow (graphic) the ETL steps with their respective tools;
  - Make project documentation;



## RUNNING THE PROJECT

```bash
# Description "pt-br"
cd Description\description.pdf 

# Read and understand the project documentation "pt-br"
cd documentation\documentation.pdf

# ETL-ITBI-Python ".ipynb" file
cd ETL-ITBI-Python\ETL-ITBI.ipynb

```
## RAW DATASETS 
[Donwload Datasets](https://drive.google.com/drive/folders/1lsa3B-lTU059I3SmQmTDvgNE0dBgL4zs?usp=sharing)

#

Gabriel Andrade

[Linkedin](https://www.linkedin.com/in/gabriel-andrade-590a17227/)
